{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a800da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals of machine learning using Python \n",
    "## Introduction to scikit-learn library\n",
    "\n",
    "***\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59432755",
   "metadata": {},
   "source": [
    "## What is Scikit-Learn (Sklearn)\n",
    "\n",
    "<img src=\"img/sklearn-logo.png\" style=\"width:300px\">\n",
    "\n",
    "* Scikit-learn (Sklearn) is the most useful and robust library for machine learning in Python.\n",
    "* It provides a selection of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction via a consistence interface in Python.\n",
    "* This library, which is largely written in Python, is built upon NumPy, SciPy and Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447cdd46",
   "metadata": {},
   "source": [
    "## Origin of Scikit-Learn\n",
    "\n",
    "* It was originally called scikits.learn and was initially developed by __David Cournapeau__ as a Google summer of code project in __2007__.\n",
    "* Later, in 2010, Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, and Vincent Michel, from FIRCA (French Institute for Research in Computer Science and Automation), took this project at another level and made the first public release (v0.1 beta) on __1st Feb. 2010__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad226a",
   "metadata": {},
   "source": [
    "## Features of Scikit-Learn\n",
    "\n",
    "* Rather than focusing on loading, manipulating and summarising data, Scikit-learn library is focused on modeling the data.\n",
    "* Some of the most popular groups of models provided by Sklearn are as follows:\n",
    "    * __Supervised Learning algorithms__ − Almost all the popular supervised learning algorithms, like Linear Regression, Support Vector Machine (SVM), Decision Tree etc., are the part of scikit-learn.\n",
    "    * __Unsupervised Learning algorithms__ − On the other hand, it also has all the popular unsupervised learning algorithms from clustering, factor analysis, PCA (Principal Component Analysis) to unsupervised neural networks.\n",
    "    * __Clustering__ − This model is used for grouping unlabeled data.\n",
    "    * __Cross Validation__ − It is used to check the accuracy of supervised models on unseen data.\n",
    "    * __Dimensionality Reduction__ − It is used for reducing the number of attributes in data which can be further used for summarisation, visualisation and feature selection.\n",
    "    * __Ensemble methods__ − As name suggest, it is used for combining the predictions of multiple supervised models.\n",
    "    * __Feature extraction__ − It is used to extract the features from data to define the attributes in image and text data.\n",
    "    * __Feature selection__ − It is used to identify useful attributes to create supervised models.\n",
    "* It is open source library and also commercially usable under BSD license."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff3540",
   "metadata": {},
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<img src=\"img/machine-learning.jpg\" style=\"width:400px\">\n",
    "\n",
    "* In general, a learning problem considers a set of $n$ objects of data and then tries to predict properties of unknown data.\n",
    "* If each sample is more than a single number and, for instance, a multi-dimensional entry (aka multivariate data), it is said to have several attributes or features.\n",
    "\n",
    "Learning problems fall into a few main categories:\n",
    "* __Supervised learning__, in which the data comes with additional attributes that we want to predict. This problem can be either:\n",
    "    * __classification__\n",
    "        * Samples belong to two or more classes and we want to learn from already labeled data how to predict the class of unlabeled data.\n",
    "        * An example of a classification problem would be handwritten digit recognition, in which the aim is to assign each input vector to one of a finite number of discrete categories.\n",
    "        * Another way to think of classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.\n",
    "    * __regression__\n",
    "         * If the desired output consists of one or more continuous variables, then the task is called regression.\n",
    "         I An example of a regression problem would be the prediction of the length of a salmon as a function of its age and weight.\n",
    "* __Unsupervised learning__, in which the training data consists of a set of input vectors $x$ without any corresponding target values. The goal in such problems may be to discover groups of similar examples within the data, where it is called __clustering__, or to determine the distribution of data within the input space, known as density estimation, or to project the data from a high-dimensional space down to two or three dimensions for the purpose of visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe975a",
   "metadata": {},
   "source": [
    "## Loading an example dataset\n",
    "\n",
    "* scikit-learn comes with a few standard datasets.\n",
    "* For instance the `iris` and `digits` datasets for classification and the `diabetes` dataset for regression.\n",
    "* In the case of classification, each loaded object has, among other things, `data` and `target` attributes containing, respectively, the values of the features of the objects in the set and their class memberships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d9675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1]]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(iris.data.shape)\n",
    "iris.data[:10], iris.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b2f2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "         15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "         12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "          0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "         10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n",
       "          9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n",
       "         15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n",
       "          0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n",
       "         16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n",
       "         14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n",
       "          1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n",
       "          0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n",
       "         16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.],\n",
       "        [ 0.,  0.,  7., 15., 13.,  1.,  0.,  0.,  0.,  8., 13.,  6., 15.,\n",
       "          4.,  0.,  0.,  0.,  2.,  1., 13., 13.,  0.,  0.,  0.,  0.,  0.,\n",
       "          2., 15., 11.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 12., 12.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1., 10.,  8.,  0.,  0.,  0.,  8.,  4.,\n",
       "          5., 14.,  9.,  0.,  0.,  0.,  7., 13., 13.,  9.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  8.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1., 13.,  6.,  2.,  2.,  0.,  0.,  0.,\n",
       "          7., 15.,  0.,  9.,  8.,  0.,  0.,  5., 16., 10.,  0., 16.,  6.,\n",
       "          0.,  0.,  4., 15., 16., 13., 16.,  1.,  0.,  0.,  0.,  0.,  3.,\n",
       "         15., 10.,  0.,  0.,  0.,  0.,  0.,  2., 16.,  4.,  0.,  0.]]),\n",
       " array([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "digits.data[:5], digits.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38709dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03807591,  0.05068012,  0.06169621,  0.02187235, -0.0442235 ,\n",
       "         -0.03482076, -0.04340085, -0.00259226,  0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, -0.02632783, -0.00844872,\n",
       "         -0.01916334,  0.07441156, -0.03949338, -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, -0.00567061, -0.04559945,\n",
       "         -0.03419447, -0.03235593, -0.00259226,  0.00286377, -0.02593034],\n",
       "        [-0.08906294, -0.04464164, -0.01159501, -0.03665645,  0.01219057,\n",
       "          0.02499059, -0.03603757,  0.03430886,  0.02269202, -0.00936191],\n",
       "        [ 0.00538306, -0.04464164, -0.03638469,  0.02187235,  0.00393485,\n",
       "          0.01559614,  0.00814208, -0.00259226, -0.03199144, -0.04664087]]),\n",
       " array([151.,  75., 141., 206., 135.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.data.shape)\n",
    "diabetes.data[:5], diabetes.target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d4e761",
   "metadata": {},
   "source": [
    "## --- Exercise ---\n",
    "\n",
    "Using the `sklearn.datasets.load_breast_cancer()` method, load the `breast cancer` dataset, check data size and feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
